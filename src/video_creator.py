"""
å‹•ç”»ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆé¸æŠå¼è³ªå•å‹•ç”»ç”¨ï¼‰
MoviePyã‚’ä½¿ç”¨ã—ã¦ç¸¦å‹ã®é¸æŠå¼è³ªå•å‹•ç”»ã‚’ç”Ÿæˆ
"""

import os
from typing import Dict, List, Optional
from moviepy import (
    VideoFileClip, ImageClip, AudioFileClip,
    TextClip, CompositeVideoClip, concatenate_videoclips,
    ColorClip
)
from moviepy import vfx
import yaml


class QuestionVideoCreator:
    """é¸æŠå¼è³ªå•å‹•ç”»ç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_path: str = "config/video_config.yaml"):
        """
        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        else:
            self.config = self._get_default_config()
        
        self.video_config = self.config['video']
        self.width = self.video_config['resolution'][0]
        self.height = self.video_config['resolution'][1]
        self.fps = self.video_config['fps']
        self.durations = self.video_config['duration']
        
        self.text_config = self.config['text_overlay']
        self.audio_config = self.config['audio']
    
    def _get_default_config(self) -> Dict:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’è¿”ã™"""
        return {
            'video': {
                'resolution': [1080, 1920],  # ç¸¦å‹
                'fps': 30,
                'duration': {
                    'opening': 6,
                    'choice': 8,
                    'ending': 5
                }
            },
            'text_overlay': {
                'font': '/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf',
                'colors': {
                    'primary': '#FFFFFF',
                    'accent': '#FFD700',
                    'background': 'rgba(0,0,0,0.7)'
                }
            },
            'audio': {
                'bgm_volume': 0.3,
                'narration_volume': 0.8,
                'sfx_volume': 0.5
            }
        }
    
    def create_question_video(
        self,
        question_data: Dict,
        choice_videos: Dict[int, str],
        output_path: str,
        bgm_path: Optional[str] = None
    ) -> str:
        """
        é¸æŠå¼è³ªå•å‹•ç”»ã‚’ç”Ÿæˆ
        
        Args:
            question_data: è³ªå•ãƒ‡ãƒ¼ã‚¿
            choice_videos: {é¸æŠè‚¢ç•ªå·: å‹•ç”»ãƒ‘ã‚¹} ã®è¾æ›¸
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            bgm_path: BGMãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        print("ğŸ¬ é¸æŠå¼è³ªå•å‹•ç”»ã‚’ç”Ÿæˆä¸­...")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # å„ãƒ‘ãƒ¼ãƒˆã‚’ç”Ÿæˆ
        opening_clip = self._create_opening(question_data)
        choice_clips = self._create_choice_sections(question_data, choice_videos)
        ending_clip = self._create_ending()
        
        # ã™ã¹ã¦ã®ã‚¯ãƒªãƒƒãƒ—ã‚’çµåˆ
        all_clips = [opening_clip] + choice_clips + [ending_clip]
        final_video = concatenate_videoclips(all_clips, method="compose")
        
        # BGMã‚’è¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if bgm_path and os.path.exists(bgm_path):
            bgm = AudioFileClip(bgm_path)
            bgm = bgm.with_effects([vfx.VolumeX(self.audio_config['bgm_volume'])])
            # ãƒ«ãƒ¼ãƒ—ã—ã¦ãƒ“ãƒ‡ã‚ªã®é•·ã•ã«åˆã‚ã›ã‚‹
            if bgm.duration < final_video.duration:
                n_loops = int(final_video.duration / bgm.duration) + 1
                bgm = concatenate_audioclips([bgm] * n_loops)
            bgm = bgm.subclip(0, final_video.duration)
            
            # æ—¢å­˜ã®éŸ³å£°ã¨ãƒŸãƒƒã‚¯ã‚¹
            if final_video.audio:
                from moviepy import CompositeAudioClip
                final_audio = CompositeAudioClip([final_video.audio, bgm])
                final_video = final_video.with_audio(final_audio)
            else:
                final_video = final_video.with_audio(bgm)
        
        # å‹•ç”»ã‚’æ›¸ãå‡ºã—
        print("ğŸ“¹ å‹•ç”»ã‚’æ›¸ãå‡ºã—ä¸­...")
        final_video.write_videofile(
            output_path,
            fps=self.fps,
            codec='libx264',
            audio_codec='aac',
            preset='medium',
            threads=4,
            logger=None  # ãƒ­ã‚°ã‚’æŠ‘åˆ¶
        )
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        final_video.close()
        for clip in all_clips:
            clip.close()
        
        print(f"âœ… å‹•ç”»ã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")
        return output_path
    
    def _create_opening(self, question_data: Dict) -> VideoFileClip:
        """ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ¼ãƒˆã‚’ä½œæˆ"""
        duration = self.durations['opening']
        
        # èƒŒæ™¯ï¼ˆé»’ï¼‰
        background = ColorClip(
            size=(self.width, self.height),
            color=(0, 0, 0),
            duration=duration
        )
        
        # è³ªå•æ–‡
        question_text = question_data.get('question', 'è³ªå•')
        context_text = question_data.get('context', '')
        
        # è³ªå•ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒƒãƒ—
        try:
            question_clip = TextClip(
                question_text,
                fontsize=80,
                color=self.text_config['colors']['accent'],
                font=self.text_config['font'],
                size=(self.width - 100, None),
                method='caption',
                align='center'
            )
            question_clip = question_clip.with_position(('center', self.height * 0.35))
            question_clip = question_clip.with_duration(duration)
            
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒƒãƒ—
            if context_text:
                context_clip = TextClip(
                    context_text,
                    fontsize=50,
                    color=self.text_config['colors']['primary'],
                    font=self.text_config['font'],
                    size=(self.width - 100, None),
                    method='caption',
                    align='center'
                )
                context_clip = context_clip.with_position(('center', self.height * 0.55))
                context_clip = context_clip.with_duration(duration)
                
                composite = CompositeVideoClip([background, question_clip, context_clip])
            else:
                composite = CompositeVideoClip([background, question_clip])
            
            # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³
            composite = composite.with_effects([vfx.FadeIn(0.5)])
            
            return composite
            
        except Exception as e:
            print(f"âš ï¸ ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return background
    
    def _create_choice_sections(
        self,
        question_data: Dict,
        choice_videos: Dict[int, str]
    ) -> List[VideoFileClip]:
        """é¸æŠè‚¢ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        choice_clips = []
        choices = question_data.get('choices', [])
        
        for choice in choices:
            number = choice['number']
            video_path = choice_videos.get(number)
            
            if video_path and os.path.exists(video_path):
                clip = self._create_single_choice(choice, video_path)
                choice_clips.append(clip)
            else:
                print(f"âš ï¸ é¸æŠè‚¢{number}ã®å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é»’ç”»é¢
                fallback = self._create_fallback_choice(choice)
                choice_clips.append(fallback)
        
        return choice_clips
    
    def _create_single_choice(self, choice: Dict, video_path: str) -> VideoFileClip:
        """1ã¤ã®é¸æŠè‚¢ã‚¯ãƒªãƒƒãƒ—ã‚’ä½œæˆ"""
        duration = self.durations['choice']
        
        # AIç”Ÿæˆå‹•ç”»ã‚’èª­ã¿è¾¼ã¿
        try:
            video = VideoFileClip(video_path)
            
            # é•·ã•ã‚’èª¿æ•´
            if video.duration < duration:
                video = video.with_effects([vfx.Loop(duration=duration)])
            else:
                video = video.subclip(0, duration)
            
            # ç¸¦å‹ã«ãƒªã‚µã‚¤ã‚º
            video = video.with_effects([vfx.Resize(height=self.height)])
            
            # ä¸­å¤®ã§ã‚¯ãƒ­ãƒƒãƒ—
            if video.w > self.width:
                x_center = video.w / 2
                x1 = x_center - self.width / 2
                video = video.with_effects([vfx.Crop(x1=x1, width=self.width)])
            
        except Exception as e:
            print(f"âš ï¸ å‹•ç”»èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            video = ColorClip(
                size=(self.width, self.height),
                color=(20, 20, 20),
                duration=duration
            )
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
        number = choice['number']
        title = choice['title']
        description = choice.get('description', '')
        
        # ç•ªå·ãƒãƒƒã‚¸
        try:
            number_text = TextClip(
                f"â¶{number}",
                fontsize=100,
                color=self.text_config['colors']['accent'],
                font=self.text_config['font']
            )
            number_text = number_text.with_position((50, 100))
            number_text = number_text.with_duration(duration)
            
            # ã‚¿ã‚¤ãƒˆãƒ«
            title_text = TextClip(
                title,
                fontsize=70,
                color=self.text_config['colors']['primary'],
                font=self.text_config['font'],
                size=(self.width - 200, None),
                method='caption',
                align='center',
                bg_color=self.text_config['colors']['background']
            )
            title_text = title_text.with_position(('center', self.height * 0.75))
            title_text = title_text.with_duration(duration)
            
            # èª¬æ˜æ–‡
            if description:
                desc_text = TextClip(
                    description,
                    fontsize=45,
                    color=self.text_config['colors']['primary'],
                    font=self.text_config['font'],
                    size=(self.width - 200, None),
                    method='caption',
                    align='center',
                    bg_color=self.text_config['colors']['background']
                )
                desc_text = desc_text.with_position(('center', self.height * 0.85))
                desc_text = desc_text.with_duration(duration)
                
                composite = CompositeVideoClip([video, number_text, title_text, desc_text])
            else:
                composite = CompositeVideoClip([video, number_text, title_text])
            
            return composite
            
        except Exception as e:
            print(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚¨ãƒ©ãƒ¼: {e}")
            return video
    
    def _create_fallback_choice(self, choice: Dict) -> VideoFileClip:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®é¸æŠè‚¢ã‚¯ãƒªãƒƒãƒ—"""
        duration = self.durations['choice']
        
        background = ColorClip(
            size=(self.width, self.height),
            color=(20, 20, 20),
            duration=duration
        )
        
        text = f"â¶{choice['number']}\n{choice['title']}"
        
        try:
            text_clip = TextClip(
                text,
                fontsize=80,
                color='white',
                font=self.text_config['font'],
                size=(self.width - 100, None),
                method='caption',
                align='center'
            )
            text_clip = text_clip.with_position('center')
            text_clip = text_clip.with_duration(duration)
            
            return CompositeVideoClip([background, text_clip])
        except:
            return background
    
    def _create_ending(self) -> VideoFileClip:
        """ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ‘ãƒ¼ãƒˆã‚’ä½œæˆ"""
        duration = self.durations['ending']
        
        # èƒŒæ™¯ï¼ˆé»’ï¼‰
        background = ColorClip(
            size=(self.width, self.height),
            color=(0, 0, 0),
            duration=duration
        )
        
        # ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒ†ã‚­ã‚¹ãƒˆ
        ending_text = "ã‚ãªãŸã¯ã©ã‚Œã‚’é¸ã‚“ã ï¼Ÿ\n\nã‚³ãƒ¡ãƒ³ãƒˆæ¬„ã§æ•™ãˆã¦ï¼"
        
        try:
            text_clip = TextClip(
                ending_text,
                fontsize=70,
                color=self.text_config['colors']['accent'],
                font=self.text_config['font'],
                size=(self.width - 100, None),
                method='caption',
                align='center'
            )
            text_clip = text_clip.with_position('center')
            text_clip = text_clip.with_duration(duration)
            
            composite = CompositeVideoClip([background, text_clip])
            
            # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
            composite = composite.with_effects([vfx.FadeOut(0.5)])
            
            return composite
            
        except Exception as e:
            print(f"âš ï¸ ã‚¨ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return background


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("QuestionVideoCreator ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_question = {
        "question": "1é€±é–“è€ãˆãŸã‚‰5å„„å††ï¼ã©ã®éƒ¨å±‹ã‚’é¸ã¶ï¼Ÿ",
        "context": "â€»1é€±é–“å¤–å‡ºç¦æ­¢ã§ã™ï¼",
        "choices": [
            {"number": 1, "title": "æ¥µå¯’ã®éƒ¨å±‹", "description": "æ°·ç‚¹ä¸‹20åº¦"},
            {"number": 2, "title": "ç¼ç†±ã®éƒ¨å±‹", "description": "æ°—æ¸©50åº¦"},
            {"number": 3, "title": "å®Œå…¨æš—é—‡", "description": "å…‰ãŒä¸€åˆ‡ãªã„"},
            {"number": 4, "title": "é¨’éŸ³åœ°ç„", "description": "24æ™‚é–“å¤§éŸ³é‡"}
        ]
    }
    
    # å‹•ç”»ãƒ‘ã‚¹ï¼ˆãƒ€ãƒŸãƒ¼ï¼‰
    test_videos = {
        1: "output/choice_1.mp4",
        2: "output/choice_2.mp4",
        3: "output/choice_3.mp4",
        4: "output/choice_4.mp4"
    }
    
    creator = QuestionVideoCreator()
    
    # å‹•ç”»ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    if any(os.path.exists(path) for path in test_videos.values()):
        output = "output/test_question_video.mp4"
        creator.create_question_video(test_question, test_videos, output)
    else:
        print("âš ï¸ ãƒ†ã‚¹ãƒˆå‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("å„é¸æŠè‚¢ã®å‹•ç”»ã‚’ output/choice_1.mp4 ã€œ choice_4.mp4 ã«é…ç½®ã—ã¦ãã ã•ã„")
